#!/usr/bin/env python3
"""
LGEEPA Adapter for Coatlicue V4.0
Adaptador para auditor√≠a de cumplimiento de la Ley General del Equilibrio Ecol√≥gico
y la Protecci√≥n al Ambiente (LGEEPA) y Normas Oficiales Mexicanas (NOMs) ambientales.

Author: Manus AI
Date: 2026-01-14
Version: 1.0
"""

import hashlib
import json
import logging
import os
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any, Optional

# Import base classes
from .regulatory_adapter import RegulatoryAdapter, AdapterConfig
from .data_structures import ProcessedDocument, AnalysisFinding, AnalysisResult

# Logging configuration
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s %(levelname)s: %(message)s"
)
logger = logging.getLogger("lgeepa_adapter")


class LGEEPAAdapter(RegulatoryAdapter):
    """
    Adaptador para auditor√≠a de cumplimiento de LGEEPA y NOMs ambientales mexicanas.
    
    Regulaci√≥n: LGEEPA (Ley General del Equilibrio Ecol√≥gico y la Protecci√≥n al Ambiente)
    Jurisdicci√≥n: M√©xico
    Agencias: SEMARNAT, PROFEPA
    
    NOMs Ambientales Principales:
    - NOM-001-SEMARNAT: L√≠mites m√°ximos permisibles de contaminantes en descargas de aguas residuales
    - NOM-052-SEMARNAT: Caracter√≠sticas, identificaci√≥n, clasificaci√≥n de residuos peligrosos
    - NOM-059-SEMARNAT: Protecci√≥n ambiental - Especies nativas de M√©xico
    - NOM-081-SEMARNAT: L√≠mites m√°ximos permisibles de emisi√≥n de ruido
    - NOM-120-SEMARNAT: Criterios y especificaciones t√©cnicas para el manejo de residuos
    - NOM-161-SEMARNAT: Clasificaci√≥n de los residuos de manejo especial
    """
    
    def __init__(self, config: AdapterConfig):
        """Inicializa el adaptador LGEEPA con configuraci√≥n espec√≠fica."""
        super().__init__(config)
        self.semarnat_forms = []  # Formatos de SEMARNAT procesados
        
    def get_name(self) -> str:
        """Retorna el nombre de la regulaci√≥n."""
        return "LGEEPA (Ley General del Equilibrio Ecol√≥gico y la Protecci√≥n al Ambiente)"
    
    def get_jurisdiction(self) -> str:
        """Retorna la jurisdicci√≥n aplicable."""
        return "M√©xico"
    
    def _initialize_rules(self):
        """
        Inicializa las reglas y principios de LGEEPA y NOMs ambientales.
        En producci√≥n, estas reglas se cargar√≠an desde una base de datos o archivo JSON.
        """
        self.lgeepa_principles = [
            {
                "id": "LGEEPA-Art15-I",
                "description": "Los ecosistemas son patrimonio com√∫n de la sociedad",
                "category": "Principios Generales"
            },
            {
                "id": "LGEEPA-Art15-IV",
                "description": "Quien realice obras o actividades que afecten el ambiente debe prevenir, minimizar o reparar los da√±os",
                "category": "Responsabilidad Ambiental"
            },
            {
                "id": "LGEEPA-Art28",
                "description": "Evaluaci√≥n del impacto ambiental",
                "category": "Evaluaci√≥n de Impacto"
            },
            {
                "id": "LGEEPA-Art35",
                "description": "Manifestaci√≥n de Impacto Ambiental (MIA)",
                "category": "Evaluaci√≥n de Impacto"
            },
        ]
        
        self.noms_ambientales = [
            {
                "id": "NOM-001-SEMARNAT-2021",
                "description": "L√≠mites m√°ximos permisibles de contaminantes en descargas de aguas residuales",
                "category": "Agua",
                "severity": "Critico"
            },
            {
                "id": "NOM-052-SEMARNAT-2005",
                "description": "Caracter√≠sticas, identificaci√≥n, clasificaci√≥n y listados de residuos peligrosos",
                "category": "Residuos Peligrosos",
                "severity": "Critico"
            },
            {
                "id": "NOM-059-SEMARNAT-2010",
                "description": "Protecci√≥n ambiental - Especies nativas de M√©xico de flora y fauna silvestres",
                "category": "Biodiversidad",
                "severity": "Alto"
            },
            {
                "id": "NOM-081-SEMARNAT-1994",
                "description": "L√≠mites m√°ximos permisibles de emisi√≥n de ruido",
                "category": "Contaminaci√≥n Ac√∫stica",
                "severity": "Medio"
            },
            {
                "id": "NOM-120-SEMARNAT-2020",
                "description": "Criterios y especificaciones t√©cnicas para el manejo de residuos de manejo especial",
                "category": "Residuos",
                "severity": "Alto"
            },
            {
                "id": "NOM-161-SEMARNAT-2011",
                "description": "Clasificaci√≥n de los residuos de manejo especial",
                "category": "Residuos",
                "severity": "Alto"
            },
        ]
        
        logger.info(f"[{self.get_name()}] Inicializadas {len(self.lgeepa_principles)} principios LGEEPA y {len(self.noms_ambientales)} NOMs ambientales")
    
    def ingest_documents(self, doc_paths: List[str]) -> List[ProcessedDocument]:
        """
        Procesa documentos ambientales, extrayendo informaci√≥n relevante y generando hashes deterministas.
        
        Args:
            doc_paths: Lista de rutas a documentos ambientales (formatos SEMARNAT, MIA, etc.)
        
        Returns:
            Lista de ProcessedDocument con informaci√≥n extra√≠da
        """
        processed_docs: List[ProcessedDocument] = []
        
        for path in doc_paths:
            logger.info(f"[{self.get_name()}] Procesando documento: {path}")
            
            try:
                # Verificar que el archivo existe
                if not os.path.exists(path):
                    logger.warning(f"Archivo no encontrado: {path}")
                    continue
                
                # Leer contenido del archivo
                with open(path, 'rb') as f:
                    content = f.read()
                
                # Calcular hash determinista (SHA-256)
                content_hash = hashlib.sha256(content).hexdigest()
                
                # Extraer metadatos del nombre del archivo
                filename = os.path.basename(path)
                metadata = {
                    "filename": filename,
                    "size_bytes": len(content),
                    "extension": os.path.splitext(filename)[1],
                    "processed_at": datetime.now().isoformat()
                }
                
                # Extraer datos estructurados (an√°lisis b√°sico)
                extracted_data = self._extract_environmental_data(path, content, filename)
                
                # Crear ProcessedDocument
                processed_doc = ProcessedDocument(
                    id=f"doc-{len(processed_docs) + 1}",
                    name=filename,
                    content_hash=content_hash,
                    metadata=metadata,
                    extracted_data=extracted_data,
                    original_path=path
                )
                
                processed_docs.append(processed_doc)
                logger.info(f"Documento procesado exitosamente: {filename} (hash: {content_hash[:16]}...)")
                
            except Exception as e:
                logger.error(f"Error procesando {path}: {e}")
                continue
        
        logger.info(f"[{self.get_name()}] Total de documentos procesados: {len(processed_docs)}")
        return processed_docs
    
    def _extract_environmental_data(self, path: str, content: bytes, filename: str) -> Dict[str, Any]:
        """
        Extrae datos ambientales estructurados del documento.
        En producci√≥n, esto usar√≠a IA (Gemini) para an√°lisis sem√°ntico.
        
        Args:
            path: Ruta del archivo
            content: Contenido binario del archivo
            filename: Nombre del archivo
        
        Returns:
            Diccionario con datos extra√≠dos
        """
        extracted = {
            "document_type": "unknown",
            "noms_mentioned": [],
            "has_mia": False,
            "has_environmental_license": False,
            "mentions_semarnat": False,
            "mentions_profepa": False,
        }
        
        # Convertir a texto para an√°lisis (simplificado)
        try:
            text_content = content.decode('utf-8', errors='ignore').lower()
        except:
            text_content = str(content).lower()
        
        # Detectar tipo de documento
        if "mia" in filename.lower() or "manifestacion" in text_content:
            extracted["document_type"] = "Manifestaci√≥n de Impacto Ambiental (MIA)"
            extracted["has_mia"] = True
        elif "licencia" in filename.lower() or "autorizacion" in text_content:
            extracted["document_type"] = "Licencia/Autorizaci√≥n Ambiental"
            extracted["has_environmental_license"] = True
        elif "formato" in filename.lower():
            extracted["document_type"] = "Formato SEMARNAT"
        
        # Detectar menciones de NOMs
        for nom in self.noms_ambientales:
            nom_id = nom["id"].lower()
            if nom_id in text_content or nom_id.replace("-", "") in text_content:
                extracted["noms_mentioned"].append(nom["id"])
        
        # Detectar menciones de agencias
        if "semarnat" in text_content:
            extracted["mentions_semarnat"] = True
        if "profepa" in text_content:
            extracted["mentions_profepa"] = True
        
        return extracted
    
    def analyze(self, processed_docs: List[ProcessedDocument]) -> AnalysisResult:
        """
        Realiza an√°lisis de cumplimiento de LGEEPA y NOMs ambientales.
        
        Args:
            processed_docs: Lista de documentos ya procesados
        
        Returns:
            AnalysisResult con hallazgos de cumplimiento
        """
        findings: List[AnalysisFinding] = []
        summary_notes: List[str] = []
        
        logger.info(f"[{self.get_name()}] Iniciando an√°lisis de {len(processed_docs)} documentos")
        
        # Verificar presencia de MIA (Manifestaci√≥n de Impacto Ambiental)
        has_mia = any(doc.extracted_data.get("has_mia", False) for doc in processed_docs)
        
        if has_mia:
            findings.append(AnalysisFinding(
                rule_id="LGEEPA-Art35",
                description="Se identific√≥ Manifestaci√≥n de Impacto Ambiental (MIA)",
                status="Cumple",
                severity="Bajo",
                context="Documento MIA presente en el expediente"
            ))
            summary_notes.append("MIA detectada")
        else:
            findings.append(AnalysisFinding(
                rule_id="LGEEPA-Art35",
                description="No se encontr√≥ Manifestaci√≥n de Impacto Ambiental (MIA)",
                status="No Cumple",
                severity="Critico",
                recommendation="Elaborar y presentar MIA ante SEMARNAT seg√∫n Art. 35 LGEEPA",
                context="Requisito obligatorio para proyectos con impacto ambiental significativo"
            ))
            summary_notes.append("MIA faltante - CR√çTICO")
        
        # Verificar presencia de licencias/autorizaciones ambientales
        has_license = any(doc.extracted_data.get("has_environmental_license", False) for doc in processed_docs)
        
        if has_license:
            findings.append(AnalysisFinding(
                rule_id="LGEEPA-Art28",
                description="Se identific√≥ licencia o autorizaci√≥n ambiental",
                status="Cumple",
                severity="Bajo"
            ))
        else:
            findings.append(AnalysisFinding(
                rule_id="LGEEPA-Art28",
                description="No se encontr√≥ licencia o autorizaci√≥n ambiental",
                status="Advertencia",
                severity="Alto",
                recommendation="Verificar si el proyecto requiere autorizaci√≥n ambiental de SEMARNAT"
            ))
        
        # Analizar cumplimiento de NOMs
        all_noms_mentioned = set()
        for doc in processed_docs:
            noms = doc.extracted_data.get("noms_mentioned", [])
            all_noms_mentioned.update(noms)
        
        if all_noms_mentioned:
            findings.append(AnalysisFinding(
                rule_id="NOMs-SEMARNAT",
                description=f"Se identificaron referencias a {len(all_noms_mentioned)} NOMs ambientales: {', '.join(sorted(all_noms_mentioned))}",
                status="Cumple",
                severity="Bajo",
                context=f"NOMs mencionadas: {', '.join(sorted(all_noms_mentioned))}"
            ))
            summary_notes.append(f"{len(all_noms_mentioned)} NOMs identificadas")
        else:
            findings.append(AnalysisFinding(
                rule_id="NOMs-SEMARNAT",
                description="No se identificaron referencias a NOMs ambientales espec√≠ficas",
                status="Advertencia",
                severity="Medio",
                recommendation="Verificar cumplimiento de NOMs aplicables seg√∫n el tipo de proyecto"
            ))
        
        # Verificar menciones de SEMARNAT/PROFEPA
        mentions_semarnat = any(doc.extracted_data.get("mentions_semarnat", False) for doc in processed_docs)
        mentions_profepa = any(doc.extracted_data.get("mentions_profepa", False) for doc in processed_docs)
        
        if mentions_semarnat or mentions_profepa:
            agencies = []
            if mentions_semarnat:
                agencies.append("SEMARNAT")
            if mentions_profepa:
                agencies.append("PROFEPA")
            
            findings.append(AnalysisFinding(
                rule_id="LGEEPA-Agencias",
                description=f"Se identificaron menciones a agencias ambientales: {', '.join(agencies)}",
                status="Cumple",
                severity="Bajo",
                context="Interacci√≥n con autoridades ambientales documentada"
            ))
        
        # Generar resumen general
        critical_findings = [f for f in findings if f.severity == "Critico"]
        high_findings = [f for f in findings if f.severity == "Alto"]
        
        if critical_findings:
            overall_summary = f"Se encontraron {len(critical_findings)} hallazgo(s) CR√çTICO(S) de incumplimiento LGEEPA/NOMs"
        elif high_findings:
            overall_summary = f"Se identificaron {len(high_findings)} advertencia(s) de ALTA severidad que requieren atenci√≥n"
        else:
            overall_summary = "Cumplimiento preliminar aparente de LGEEPA y NOMs ambientales"
        
        logger.info(f"[{self.get_name()}] An√°lisis completado: {len(findings)} hallazgos")
        
        return AnalysisResult(
            regulation_name=self.get_name(),
            jurisdiction=self.get_jurisdiction(),
            summary=overall_summary,
            findings=findings,
            timestamp=datetime.now().isoformat()
        )
    
    def render_report_summary(self, analysis_result: AnalysisResult) -> str:
        """
        Genera un resumen del reporte de cumplimiento LGEEPA.
        
        Args:
            analysis_result: Resultado del an√°lisis
        
        Returns:
            String con el reporte formateado
        """
        summary_str = f"# Reporte de Cumplimiento Ambiental\n"
        summary_str += f"## {analysis_result.regulation_name}\n\n"
        summary_str += f"**Jurisdicci√≥n**: {analysis_result.jurisdiction}\n"
        summary_str += f"**Fecha del An√°lisis**: {analysis_result.timestamp}\n"
        summary_str += f"**Agencias Competentes**: SEMARNAT, PROFEPA\n\n"
        summary_str += f"---\n\n"
        summary_str += f"### Resumen Ejecutivo\n\n"
        summary_str += f"{analysis_result.summary}\n\n"
        summary_str += f"---\n\n"
        summary_str += f"### Hallazgos Detallados\n\n"
        
        # Agrupar hallazgos por severidad
        critical = [f for f in analysis_result.findings if f.severity == "Critico"]
        high = [f for f in analysis_result.findings if f.severity == "Alto"]
        medium = [f for f in analysis_result.findings if f.severity == "Medio"]
        low = [f for f in analysis_result.findings if f.severity == "Bajo"]
        
        if critical:
            summary_str += f"#### üî¥ Hallazgos Cr√≠ticos ({len(critical)})\n\n"
            for finding in critical:
                summary_str += f"- **[{finding.status}]** {finding.description}\n"
                summary_str += f"  - **Regla**: {finding.rule_id}\n"
                if finding.context:
                    summary_str += f"  - **Contexto**: {finding.context}\n"
                if finding.recommendation:
                    summary_str += f"  - **Recomendaci√≥n**: {finding.recommendation}\n"
                summary_str += "\n"
        
        if high:
            summary_str += f"#### üü† Hallazgos de Alta Severidad ({len(high)})\n\n"
            for finding in high:
                summary_str += f"- **[{finding.status}]** {finding.description}\n"
                summary_str += f"  - **Regla**: {finding.rule_id}\n"
                if finding.recommendation:
                    summary_str += f"  - **Recomendaci√≥n**: {finding.recommendation}\n"
                summary_str += "\n"
        
        if medium:
            summary_str += f"#### üü° Hallazgos de Severidad Media ({len(medium)})\n\n"
            for finding in medium:
                summary_str += f"- **[{finding.status}]** {finding.description} ({finding.rule_id})\n"
        
        if low:
            summary_str += f"\n#### üü¢ Hallazgos de Baja Severidad / Cumplimientos ({len(low)})\n\n"
            for finding in low:
                summary_str += f"- **[{finding.status}]** {finding.description} ({finding.rule_id})\n"
        
        summary_str += f"\n---\n\n"
        summary_str += f"### Estad√≠sticas\n\n"
        summary_str += f"- **Total de hallazgos**: {len(analysis_result.findings)}\n"
        summary_str += f"- **Cr√≠ticos**: {len(critical)}\n"
        summary_str += f"- **Altos**: {len(high)}\n"
        summary_str += f"- **Medios**: {len(medium)}\n"
        summary_str += f"- **Bajos**: {len(low)}\n\n"
        
        summary_str += f"---\n\n"
        summary_str += f"*Reporte generado por Coatlicue V4.0 - Sistema de Auditor√≠a Ambiental*\n"
        summary_str += f"*Validez Legal: NOM-151-SCFI-2016 + Blockchain Bitcoin*\n"
        
        return summary_str


# Funci√≥n de utilidad para ejecutar el adaptador
def main():
    """Funci√≥n principal para pruebas del adaptador LGEEPA."""
    print("=== LGEEPA Adapter - Prueba ===\n")
    
    # Configuraci√≥n
    config = AdapterConfig(language="es")
    
    # Crear adaptador
    adapter = LGEEPAAdapter(config)
    
    print(f"Adaptador: {adapter.get_name()}")
    print(f"Jurisdicci√≥n: {adapter.get_jurisdiction()}\n")
    
    # Simular ingesta de documentos
    # En producci√≥n, estos ser√≠an los formatos descargados de SEMARNAT
    doc_paths = [
        "formatos_descargados/formato-14-ambiental.pdf",
        "formatos_descargados/formato-15-residuos.pdf",
        "formatos_descargados/MIA-proyecto-ejemplo.pdf",
    ]
    
    print("Documentos a procesar (simulados):")
    for path in doc_paths:
        print(f"  - {path}")
    print()
    
    # Nota: En este ejemplo no procesamos archivos reales
    # processed_docs = adapter.ingest_documents(doc_paths)
    
    print("‚úÖ Adaptador LGEEPA listo para producci√≥n")
    print("\nPara usar:")
    print("  1. adapter.ingest_documents(rutas_a_documentos)")
    print("  2. adapter.analyze(documentos_procesados)")
    print("  3. adapter.render_report_summary(resultado)")


if __name__ == "__main__":
    main()
